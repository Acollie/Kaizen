# ðŸ—ï¸ Kaizen Architecture Guide

Deep dive into how Kaizen is designed, built, and extended.

## Table of Contents

1. [System Overview](#system-overview)
2. [Core Design Patterns](#core-design-patterns)
3. [Project Structure](#project-structure)
4. [Analysis Pipeline](#analysis-pipeline)
5. [Metric Calculations](#metric-calculations)
6. [Storage & Persistence](#storage--persistence)
7. [Language Support](#language-support)
8. [Adding New Languages](#adding-new-languages)
9. [Performance Considerations](#performance-considerations)

---

## System Overview

### High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Kaizen CLI (Cobra)                      â”‚
â”‚  analyze | visualize | diff | trend | report | history     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
        â”‚              â”‚
    â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”
    â”‚ Config â”‚    â”‚ Churn   â”‚
    â”‚ Parser â”‚    â”‚Analyzer â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
                       â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚                     â”‚
        â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”
        â”‚ Language â”‚      â”‚   Git   â”‚
        â”‚Registry  â”‚      â”‚  Cmds   â”‚
        â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                 â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â–¼â”€â”€â”€â”
â”‚   Go   â”‚ Kt â”‚ Sw â”‚ Py.. â”‚
â”‚  ast   â”‚TS  â”‚TS  â”‚ Stub â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”´â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”˜
           â”‚
      â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
      â”‚ Analysis â”‚
      â”‚ Result   â”‚
      â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
           â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
    â”‚             â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”      â”Œâ”€â”€â”€â–¼â”€â”€â”
â”‚SQLiteâ”‚      â”‚HTML  â”‚
â”‚ DB   â”‚      â”‚  /   â”‚
â”‚      â”‚      â”‚JSON  â”‚
â””â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”˜
```

### Key Components

| Component | Purpose | Technology |
|-----------|---------|------------|
| **Pipeline** | Orchestrate analysis | Go goroutines |
| **Language Analyzers** | Parse code | go/ast, tree-sitter |
| **Aggregator** | Roll up metrics | Custom calculation |
| **Churn Analyzer** | Git history | Git CLI + parsing |
| **Storage Backend** | Persist results | SQLite + GORM |
| **Visualizations** | Display results | D3.js, HTML/CSS |
| **CLI** | User interface | Cobra framework |

---

## Core Design Patterns

### 1. **Interface-Based Language Analyzers**

All language support follows this interface:

```go
type LanguageAnalyzer interface {
    Name() string
    FileExtensions() []string
    CanAnalyze(filePath string) bool
    AnalyzeFile(filePath string) (*models.FileAnalysis, error)
    IsStub() bool
}
```

**Benefits:**
- âœ… Easy to add new languages
- âœ… No coupling between languages
- âœ… Can run in parallel
- âœ… Simple testing

### 2. **FunctionNode Pattern**

Language-specific function analysis:

```go
type FunctionNode interface {
    CalculateCyclomaticComplexity() int
    CalculateCognitiveComplexity() int
    CalculateNestingDepth() int
}
```

**Benefits:**
- âœ… Consistent complexity metrics across languages
- âœ… Language-specific optimizations
- âœ… AST-aware calculations

### 3. **Storage Backend Interface**

Multiple storage options:

```go
type StorageBackend interface {
    Save(snapshot *AnalysisResult) error
    GetLatest() (*AnalysisResult, error)
    GetTimeSeries(metric string, days int) ([]DataPoint, error)
    // ...
}
```

**Implementations:**
- SQLite (current)
- JSON files (backup)
- Ready for cloud storage (S3, etc.)

### 4. **Configuration Priority**

```
CLI Flags > .kaizen.yaml > .kaizenignore > Defaults
```

Allows flexibility from simple to complex configs.

---

## Project Structure

```
kaizen/
â”œâ”€â”€ cmd/
â”‚   â””â”€â”€ kaizen/           # CLI entry point
â”‚       â”œâ”€â”€ main.go       # Cobra command setup
â”‚       â”œâ”€â”€ analyze.go    # analyze command
â”‚       â”œâ”€â”€ visualize.go  # visualize command
â”‚       â”œâ”€â”€ diff.go       # diff command (new)
â”‚       â””â”€â”€ ...
â”‚
â”œâ”€â”€ pkg/
â”‚   â”œâ”€â”€ models/           # Data structures
â”‚   â”‚   â””â”€â”€ models.go     # FileAnalysis, FunctionAnalysis, etc.
â”‚   â”‚
â”‚   â”œâ”€â”€ analyzer/         # Core analysis engine
â”‚   â”‚   â”œâ”€â”€ pipeline.go   # Analysis orchestrator
â”‚   â”‚   â”œâ”€â”€ aggregator.go # Metric aggregation
â”‚   â”‚   â”œâ”€â”€ interfaces.go # LanguageAnalyzer, FunctionNode
â”‚   â”‚   â””â”€â”€ *_test.go     # Tests
â”‚   â”‚
â”‚   â”œâ”€â”€ languages/        # Multi-language support
â”‚   â”‚   â”œâ”€â”€ registry.go   # Language registration
â”‚   â”‚   â”œâ”€â”€ golang/       # Go analyzer (ast-based)
â”‚   â”‚   â”œâ”€â”€ kotlin/       # Kotlin analyzer (tree-sitter)
â”‚   â”‚   â”œâ”€â”€ swift/        # Swift analyzer (tree-sitter)
â”‚   â”‚   â””â”€â”€ python/       # Python stub
â”‚   â”‚
â”‚   â”œâ”€â”€ churn/            # Git integration
â”‚   â”‚   â”œâ”€â”€ analyzer.go   # Calculate churn metrics
â”‚   â”‚   â””â”€â”€ *_test.go
â”‚   â”‚
â”‚   â”œâ”€â”€ storage/          # Persistence layer
â”‚   â”‚   â”œâ”€â”€ interface.go  # StorageBackend interface
â”‚   â”‚   â”œâ”€â”€ sqlite.go     # SQLite implementation
â”‚   â”‚   â”œâ”€â”€ migrations.go # Database schema
â”‚   â”‚   â””â”€â”€ *_test.go
â”‚   â”‚
â”‚   â”œâ”€â”€ visualization/    # Output generation
â”‚   â”‚   â”œâ”€â”€ html.go       # Interactive treemap
â”‚   â”‚   â”œâ”€â”€ sankey.go     # Ownership diagrams
â”‚   â”‚   â”œâ”€â”€ terminal.go   # ASCII output
â”‚   â”‚   â””â”€â”€ *_test.go
â”‚   â”‚
â”‚   â”œâ”€â”€ reports/          # Reporting
â”‚   â”‚   â”œâ”€â”€ scorer.go     # Grade calculation
â”‚   â”‚   â”œâ”€â”€ grading.go    # A-F grading
â”‚   â”‚   â”œâ”€â”€ concerns.go   # Issue detection
â”‚   â”‚   â””â”€â”€ *_test.go
â”‚   â”‚
â”‚   â”œâ”€â”€ ownership/        # CODEOWNERS integration
â”‚   â”‚   â”œâ”€â”€ parser.go     # Parse CODEOWNERS
â”‚   â”‚   â”œâ”€â”€ aggregator.go # Team metrics
â”‚   â”‚   â”œâ”€â”€ reporter.go   # Generate reports
â”‚   â”‚   â””â”€â”€ *_test.go
â”‚   â”‚
â”‚   â””â”€â”€ trending/         # Historical analysis
â”‚       â”œâ”€â”€ ascii.go      # Terminal trends
â”‚       â”œâ”€â”€ html.go       # Interactive charts
â”‚       â”œâ”€â”€ json.go       # JSON export
â”‚       â””â”€â”€ *_test.go
â”‚
â”œâ”€â”€ internal/
â”‚   â””â”€â”€ config/           # Configuration loading
â”‚       â””â”€â”€ config.go     # .kaizen.yaml parsing
â”‚
â”œâ”€â”€ demo/                 # Demo project
â”‚   â””â”€â”€ sample-project/   # Example code
â”‚
â”œâ”€â”€ .github/
â”‚   â”œâ”€â”€ workflows/        # CI/CD
â”‚   â”œâ”€â”€ ISSUE_TEMPLATE/   # Issue templates
â”‚   â””â”€â”€ PULL_REQUEST_TEMPLATE.md
â”‚
â”œâ”€â”€ CLAUDE.md             # AI guidelines
â”œâ”€â”€ README.md             # Main documentation
â”œâ”€â”€ GUIDE.md              # Usage guide
â”œâ”€â”€ ARCHITECTURE.md       # This file
â”œâ”€â”€ CONTRIBUTING.md       # Contribution guidelines
â”œâ”€â”€ CODE_OF_CONDUCT.md    # Community standards
â”œâ”€â”€ LICENSE               # MIT license
â”œâ”€â”€ SECURITY.md           # Security policy
â”œâ”€â”€ CHANGELOG.md          # Version history
â””â”€â”€ go.mod / go.sum       # Dependencies
```

---

## Analysis Pipeline

### Step-by-Step Flow

```
1. Configuration Loading
   â””â”€ Load .kaizen.yaml, .kaizenignore, CLI flags

2. File Discovery
   â””â”€ Walk directory tree, apply ignore patterns

3. Language Detection
   â””â”€ Match extension to analyzer via Registry

4. File Analysis (parallel)
   â”œâ”€ Go AST â†’ FunctionAnalysis[]
   â”œâ”€ Kotlin Tree-sitter â†’ FunctionAnalysis[]
   â”œâ”€ Swift Tree-sitter â†’ FunctionAnalysis[]
   â””â”€ Python â†’ (stub)

5. Churn Analysis (parallel)
   â”œâ”€ git log --numstat (file-level)
   â””â”€ git log -L (function-level)

6. Aggregation
   â””â”€ Roll up metrics by folder hierarchy

7. Scoring & Grading
   â”œâ”€ Calculate component scores
   â”œâ”€ Generate A-F grade
   â””â”€ Detect areas of concern

8. Persistence
   â”œâ”€ Save to SQLite
   â””â”€ Save JSON backup (optional)

9. Output
   â”œâ”€ Generate visualizations
   â”œâ”€ Print to terminal
   â””â”€ Return results
```

### Code: Pipeline Execution

```go
// pkg/analyzer/pipeline.go
func (pipeline *Pipeline) Analyze(options AnalysisOptions) (*AnalysisResult, error) {
    // 1. Discover files
    files := pipeline.discoverFiles(options.RootPath)

    // 2. Analyze in parallel
    results := make(chan *FileAnalysis, len(files))
    for _, file := range files {
        go pipeline.analyzeFile(file, results)
    }

    // 3. Aggregate
    aggregated := pipeline.aggregator.Aggregate(fileAnalyses)

    // 4. Score
    scored := pipeline.score(aggregated)

    return scored, nil
}
```

---

## Metric Calculations

### Cyclomatic Complexity (CC)

**Definition:** Counts linearly independent paths through code

**Formula:** CC = 1 + Î£(decision points)

**Implementation:**

```go
// Count decision points in AST
cyclomatic := 1

ast.Inspect(funcNode, func(n ast.Node) bool {
    switch n.(type) {
    case *ast.IfStmt, *ast.ForStmt, *ast.CaseClause:
        cyclomatic++
    case *ast.BinaryExpr:
        if expr.Op == token.LAND || expr.Op == token.LOR {
            cyclomatic++
        }
    }
    return true
})
```

**Interpretation:**
- 1-5: Low complexity (good)
- 6-10: Moderate (acceptable)
- 11-15: High (review)
- 16+: Very high (refactor)

### Cognitive Complexity

**Definition:** CC with nesting penalty

**Formula:** CC + (nesting_level Ã— bonus) per decision

**Implementation:**

```go
cognitive := 0
nestingLevel := 0

// For each decision point:
// cognitive += 1 + nestingLevel
// If entering nested block:
//   nestingLevel++
```

**Comparison:**

```go
// CC = 3, Cognitive = 6
if a {      // +1 CC, +1 Cognitive
    if b {  // +1 CC, +2 Cognitive (nested)
        if c { // +1 CC, +3 Cognitive (doubly nested)
            do()
        }
    }
}
```

### Halstead Metrics

**Operators:** Keywords, operators (`+`, `-`, `=`, etc.)
**Operands:** Variables, literals

**Metrics:**
- Vocabulary = # unique operators + # unique operands
- Length = total tokens
- Volume = Length Ã— logâ‚‚(Vocabulary)
- Difficulty = (unique operators / 2) Ã— (total operands / unique operands)
- Effort = Difficulty Ã— Volume

**Implementation:**

```go
volume := float64(totalTokens) * math.Log2(float64(vocabulary))
difficulty := (float64(uniqueOps) / 2.0) * (float64(totalOps) / float64(uniqueOps))
effort := difficulty * volume
```

### Maintainability Index (MI)

**Definition:** How easy is code to maintain?

**Formula:** `171 - 5.2Ã—ln(HalsteadVolume) - 0.23Ã—CC - 16.2Ã—ln(LOC)`

**Range:** 0-100
- 85-100: Easy to maintain
- 50-84: Moderate
- 0-49: Difficult

**Implementation:**

```go
mi := 171 -
    (5.2 * math.Log(halsteadVolume)) -
    (0.23 * float64(complexity)) -
    (16.2 * math.Log(float64(loc)))

mi = math.Max(0, math.Min(100, mi)) // Clamp to 0-100
```

### Hotspot Detection

**Definition:** High-churn + High-complexity code

**Formula:**
```
Hotspot = (complexity > threshold) AND (churn > threshold)
```

**Thresholds:**
- Complexity > 10
- Churn > 10 commits

**Why:** These are pain points needing immediate attention

---

## Storage & Persistence

### SQLite Schema

```sql
-- Snapshots - each analysis run
snapshots
â”œâ”€â”€ id (PK)
â”œâ”€â”€ analyzed_at (timestamp)
â”œâ”€â”€ overall_score (float)
â””â”€â”€ metadata (json)

-- File metrics per snapshot
folder_metrics
â”œâ”€â”€ id (PK)
â”œâ”€â”€ snapshot_id (FK)
â”œâ”€â”€ scope_path (string)
â”œâ”€â”€ file_count (int)
â”œâ”€â”€ avg_complexity (float)
â””â”€â”€ ...

-- Function-level metrics
function_metrics
â”œâ”€â”€ id (PK)
â”œâ”€â”€ file_path (string)
â”œâ”€â”€ function_name (string)
â”œâ”€â”€ complexity (int)
â”œâ”€â”€ churn (int)
â””â”€â”€ ...

-- Team ownership
file_ownership
â”œâ”€â”€ id (PK)
â”œâ”€â”€ file_path (string)
â”œâ”€â”€ owner (string)
â””â”€â”€ ...
```

### Data Persistence

```go
// Single interface for all storage
type StorageBackend interface {
    Save(result *AnalysisResult) (int64, error)
    GetLatest() (*AnalysisResult, error)
    GetLatestSummary() (*SnapshotSummary, error)
    GetTimeSeries(metric string, days int) ([]DataPoint, error)
    GetByID(id int64) (*AnalysisResult, error)
    Prune(keepDays int) error
}

// SQLite implementation
type SQLiteBackend struct {
    db *gorm.DB
}
```

---

## Language Support

### Supported Languages

#### Go âœ… Full Support

**Parser:** `go/ast` (built-in)
- Native Go package
- No external dependencies
- Very reliable

**Analyzer:** `pkg/languages/golang/analyzer.go`
- Uses `ast.Inspect()` for tree walking
- Type switches for AST node handling
- Native support for Go semantics

**Metrics:**
- CC: counts `if`, `for`, `switch case`, `&&`, `||`
- MI: calculated from LOC, CC, volume
- 95%+ coverage

#### Kotlin âœ… Full Support

**Parser:** Tree-sitter (github.com/smacker/go-tree-sitter/kotlin)
- AST-based parsing
- Cursor-based traversal
- Comprehensive node types

**Analyzer:** `pkg/languages/kotlin/analyzer.go`
- Identifies `function_declaration` nodes
- Extracts parameters, complexity
- Handles class/interface definitions

**Metrics:**
- CC: counts `if`, `when`, `for`, `while`, `try-catch`
- MI: calculated similarly to Go
- 90%+ coverage

#### Swift âœ… Full Support

**Parser:** Tree-sitter (github.com/smacker/go-tree-sitter/swift)
- AST-based parsing
- Robust Swift syntax support

**Analyzer:** `pkg/languages/swift/analyzer.go`
- Identifies `function_declaration` nodes
- Extracts parameter count
- Detects types (struct, class, protocol, enum)

**Metrics:**
- CC: counts `if`, `guard`, `for`, `while`, `switch`
- Cognitive: adds nesting penalty
- 90%+ coverage

#### Python ðŸš§ Stub

**Status:** Ready for implementation
**Parser:** Tree-sitter (available)
**Next Steps:** Follow Swift/Kotlin pattern

---

## Adding New Languages

### Step 1: Create Language Package

```bash
mkdir -p pkg/languages/python
cd pkg/languages/python
```

### Step 2: Implement LanguageAnalyzer Interface

```go
// pkg/languages/python/analyzer.go
package python

import "github.com/smacker/go-tree-sitter"
import "github.com/smacker/go-tree-sitter/python"

type PythonAnalyzer struct {
    language *sitter.Language
}

func NewPythonAnalyzer() analyzer.LanguageAnalyzer {
    return &PythonAnalyzer{
        language: python.GetLanguage(),
    }
}

func (pa *PythonAnalyzer) Name() string { return "Python" }
func (pa *PythonAnalyzer) FileExtensions() []string { return []string{".py"} }
func (pa *PythonAnalyzer) CanAnalyze(filePath string) bool { ... }
func (pa *PythonAnalyzer) IsStub() bool { return false }

func (pa *PythonAnalyzer) AnalyzeFile(filePath string) (*models.FileAnalysis, error) {
    // 1. Read source
    sourceBytes, _ := os.ReadFile(filePath)

    // 2. Parse with tree-sitter
    parser := sitter.NewParser()
    parser.SetLanguage(pa.language)
    tree := parser.Parse(nil, sourceBytes)

    // 3. Extract functions
    functions := pa.extractFunctions(tree.RootNode(), sourceBytes)

    // 4. Return analysis
    return &models.FileAnalysis{
        Language: "Python",
        Functions: functions,
        // ...
    }, nil
}

func (pa *PythonAnalyzer) extractFunctions(node *sitter.Node, src []byte) []models.FunctionAnalysis {
    // Recursive AST walk looking for "function_definition" nodes
    // ...
}
```

### Step 3: Implement Complexity Calculation

```go
// pkg/languages/python/function.go
package python

type PythonFunction struct {
    node        *sitter.Node
    sourceBytes []byte
}

func (pf *PythonFunction) CalculateCyclomaticComplexity() int {
    complexity := 1
    // Count: if, elif, except, for, while, and, or, comprehensions
    // ...
    return complexity
}

func (pf *PythonFunction) CalculateCognitiveComplexity() int {
    // Like CC but with nesting penalty
    // ...
}

func (pf *PythonFunction) CalculateNestingDepth() int {
    // Track max indentation level
    // ...
}
```

### Step 4: Register in Registry

```go
// pkg/languages/registry.go
import "github.com/alexcollie/kaizen/pkg/languages/python"

func NewRegistry() *Registry {
    return &Registry{
        analyzers: []analyzer.LanguageAnalyzer{
            golang.NewGoAnalyzer(),
            kotlin.NewKotlinAnalyzer(),
            swift.NewSwiftAnalyzer(),
            python.NewPythonAnalyzer(),  // ADD THIS
        },
    }
}
```

### Step 5: Write Tests

```go
// pkg/languages/python/analyzer_test.go
package python

func TestCanAnalyze(t *testing.T) {
    analyzer := NewPythonAnalyzer()
    assert.True(t, analyzer.CanAnalyze("test.py"))
}

func TestAnalyzeFile(t *testing.T) {
    // Create test.py with sample code
    // Analyze it
    // Check results
}
```

### Step 6: Update Documentation

- Add to README.md language table
- Document any language-specific considerations
- Add examples to GUIDE.md

### Step 7: Submit PR

All done! Your new language will automatically work with:
- âœ… `kaizen analyze`
- âœ… `kaizen visualize`
- âœ… `kaizen diff`
- âœ… `kaizen trend`
- âœ… Team ownership reports

---

## Performance Considerations

### Optimization Strategies

#### 1. Parallel File Analysis

```go
// Process files in parallel
results := make(chan *FileAnalysis, len(files))
for _, file := range files {
    go pipeline.analyzeFile(file, results)
}
```

**Speedup:** Near-linear with CPU cores

#### 2. Skip Expensive Operations

```bash
# Skip git churn analysis (can be slow on large repos)
kaizen analyze --path=. --skip-churn

# Add it later
kaizen analyze --path=.  # Full analysis
```

**Speedup:** 5-10x on large repos

#### 3. Incremental Analysis

**Future feature:** Only re-analyze changed files

#### 4. Caching

**Future feature:** Cache AST parsing results

### Typical Performance

| Project | Files | LOC | Time | Notes |
|---------|-------|-----|------|-------|
| Small | 10 | 1K | 0.1s | Very fast |
| Medium | 100 | 20K | 0.5s | Includes churn |
| Large | 1K | 200K | 3s | Full analysis |
| XL | 10K | 2M | 20s | With git history |

### Profiling

```bash
# Build with profiling
go build -o kaizen ./cmd/kaizen

# Run with CPU profiling
go test -cpuprofile=cpu.prof ./...
go tool pprof cpu.prof

# Memory profiling
go test -memprofile=mem.prof ./...
go tool pprof mem.prof
```

---

## Key Design Decisions

### 1. Interface-Based Languages

**Decision:** All languages implement common interface
**Rationale:**
- Easy to add languages without modifying core
- Clear contract for new implementations
- Testable independently

### 2. Tree-Sitter for New Languages

**Decision:** Use tree-sitter instead of language-specific parsers
**Rationale:**
- Consistent across languages
- Reliable AST parsing
- Maintained community parsers

### 3. SQLite for Storage

**Decision:** SQLite instead of other databases
**Rationale:**
- Zero-config (embedded)
- Good for time-series
- File-based (portable)

### 4. Cobra for CLI

**Decision:** Cobra framework for CLI
**Rationale:**
- Professional, battle-tested
- Great help/completion
- Flag management

---

## Future Architecture Improvements

- **Distributed Analysis:** Process massive codebases across machines
- **Incremental Analysis:** Only re-parse changed files
- **Caching Layer:** Cache AST parsing results
- **Custom Metrics:** Plugin system for organization-specific metrics
- **Cloud Storage:** S3/Cloud backend support
- **Web Dashboard:** Real-time monitoring interface

---

## Contributing to Architecture

Want to improve Kaizen's internals?

1. **File Issues** - Discuss major changes first
2. **Benchmarks** - Show performance impact
3. **Tests** - All changes need tests
4. **Documentation** - Update ARCHITECTURE.md
5. **PR** - Reference issue, explain rationale

See [CONTRIBUTING.md](./CONTRIBUTING.md) for details.

